{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.linear_model import Ridge\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_selection import mutual_info_classif\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\n\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\n%matplotlib inline","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-30T09:30:33.383197Z","iopub.execute_input":"2023-09-30T09:30:33.383567Z","iopub.status.idle":"2023-09-30T09:30:34.475159Z","shell.execute_reply.started":"2023-09-30T09:30:33.383539Z","shell.execute_reply":"2023-09-30T09:30:34.474023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"url = \"https://raw.githubusercontent.com/alexeygrigorev/mlbookcamp-code/master/chapter-02-car-price/data.csv\"\ndata = pd.read_csv(url)","metadata":{"execution":{"iopub.status.busy":"2023-09-30T09:30:34.477492Z","iopub.execute_input":"2023-09-30T09:30:34.478480Z","iopub.status.idle":"2023-09-30T09:30:35.732231Z","shell.execute_reply.started":"2023-09-30T09:30:34.478434Z","shell.execute_reply":"2023-09-30T09:30:35.730961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-30T09:30:35.733538Z","iopub.execute_input":"2023-09-30T09:30:35.733869Z","iopub.status.idle":"2023-09-30T09:30:35.755995Z","shell.execute_reply.started":"2023-09-30T09:30:35.733843Z","shell.execute_reply":"2023-09-30T09:30:35.754769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Features**","metadata":{}},{"cell_type":"code","source":"selected_features = [\n    'Make', 'Model', 'Year', 'Engine HP', 'Engine Cylinders',\n    'Transmission Type', 'Vehicle Style', 'highway MPG', 'city mpg', 'MSRP'\n]\ndata = data[selected_features]","metadata":{"execution":{"iopub.status.busy":"2023-09-30T09:30:35.758883Z","iopub.execute_input":"2023-09-30T09:30:35.759619Z","iopub.status.idle":"2023-09-30T09:30:35.766135Z","shell.execute_reply.started":"2023-09-30T09:30:35.759576Z","shell.execute_reply":"2023-09-30T09:30:35.765318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"execution":{"iopub.status.busy":"2023-09-30T09:30:35.767180Z","iopub.execute_input":"2023-09-30T09:30:35.768054Z","iopub.status.idle":"2023-09-30T09:30:35.799261Z","shell.execute_reply.started":"2023-09-30T09:30:35.768022Z","shell.execute_reply":"2023-09-30T09:30:35.798518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Data preparation**","metadata":{}},{"cell_type":"code","source":"data.columns = data.columns.str.replace(' ', '_').str.lower()\n\n# Fill missing values with 0\ndata.fillna(0, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-30T09:30:35.800683Z","iopub.execute_input":"2023-09-30T09:30:35.801256Z","iopub.status.idle":"2023-09-30T09:30:35.815720Z","shell.execute_reply.started":"2023-09-30T09:30:35.801229Z","shell.execute_reply":"2023-09-30T09:30:35.814638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Rename MSRP to price\ndata.rename(columns={'msrp': 'price'}, inplace=True)\ndata","metadata":{"execution":{"iopub.status.busy":"2023-09-30T09:30:35.817288Z","iopub.execute_input":"2023-09-30T09:30:35.817684Z","iopub.status.idle":"2023-09-30T09:30:35.846383Z","shell.execute_reply.started":"2023-09-30T09:30:35.817646Z","shell.execute_reply":"2023-09-30T09:30:35.845311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Question 1: Most Frequent Transmission Type**\nWhat is the most frequent observation (mode) for the column transmission_type?","metadata":{}},{"cell_type":"code","source":"most_frequent_transmission = data['transmission_type'].mode()[0]\nprint(\"The most frequent observation for 'transmission_type' is:\", most_frequent_transmission)","metadata":{"execution":{"iopub.status.busy":"2023-09-30T09:30:35.847560Z","iopub.execute_input":"2023-09-30T09:30:35.847868Z","iopub.status.idle":"2023-09-30T09:30:35.854904Z","shell.execute_reply.started":"2023-09-30T09:30:35.847842Z","shell.execute_reply":"2023-09-30T09:30:35.853792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Question 2: Correlation Matrix**","metadata":{}},{"cell_type":"code","source":"# Calculate the correlation matrix for the numerical features\nnumerical_features = data[['year', 'engine_hp', 'engine_cylinders', 'highway_mpg', 'city_mpg']]\ncorrelation_matrix = numerical_features.corr()\n\n# Adjusting the matrix style for better visualisation\nplt.figure(figsize=(10, 6))\nsns.set(font_scale=1.2)\nsns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=0.5)\nplt.title(\"Correlation matrix of numerical features\")\nplt.show()\n\n# Let's find two traits with the highest correlation\nmax_corr = correlation_matrix.abs().unstack().sort_values(ascending=False)\nmax_corr = max_corr[max_corr != 1] \nfeature1, feature2 = max_corr.index[0]\n\nprint(f\"Two traits with the highest correlation: '{feature1}' Ð¸ '{feature2}' with a correlation coefficient {correlation_matrix.loc[feature1, feature2]}\")","metadata":{"execution":{"iopub.status.busy":"2023-09-30T09:30:35.856387Z","iopub.execute_input":"2023-09-30T09:30:35.856909Z","iopub.status.idle":"2023-09-30T09:30:36.332662Z","shell.execute_reply.started":"2023-09-30T09:30:35.856878Z","shell.execute_reply":"2023-09-30T09:30:36.331625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Make price binary**","metadata":{}},{"cell_type":"code","source":"# Create a binary variable above_average\ndata['above_average'] = (data['price'] > data['price'].mean()).astype(int)","metadata":{"execution":{"iopub.status.busy":"2023-09-30T09:30:36.335659Z","iopub.execute_input":"2023-09-30T09:30:36.336005Z","iopub.status.idle":"2023-09-30T09:30:36.343339Z","shell.execute_reply.started":"2023-09-30T09:30:36.335974Z","shell.execute_reply":"2023-09-30T09:30:36.342021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-30T09:30:36.344604Z","iopub.execute_input":"2023-09-30T09:30:36.345023Z","iopub.status.idle":"2023-09-30T09:30:36.372006Z","shell.execute_reply.started":"2023-09-30T09:30:36.344994Z","shell.execute_reply":"2023-09-30T09:30:36.370655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Split the data**","metadata":{}},{"cell_type":"code","source":"# Split the data into train, validation, and test sets\nX = data.drop(columns=['above_average'])\ny = data['above_average']\nX_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\nX_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-30T09:30:36.373493Z","iopub.execute_input":"2023-09-30T09:30:36.373806Z","iopub.status.idle":"2023-09-30T09:30:36.392005Z","shell.execute_reply.started":"2023-09-30T09:30:36.373781Z","shell.execute_reply":"2023-09-30T09:30:36.390781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display the shapes of the resulting sets\nprint(\"Train set shape:\", X_train.shape, y_train.shape)\nprint(\"Validation set shape:\", X_val.shape, y_val.shape)\nprint(\"Test set shape:\", X_test.shape, y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2023-09-30T09:30:36.393079Z","iopub.execute_input":"2023-09-30T09:30:36.393965Z","iopub.status.idle":"2023-09-30T09:30:36.404851Z","shell.execute_reply.started":"2023-09-30T09:30:36.393931Z","shell.execute_reply":"2023-09-30T09:30:36.403792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Question 3**","metadata":{}},{"cell_type":"code","source":"# Define the list of categorical features\ncategorical_features = ['make', 'model', 'transmission_type', 'vehicle_style']\n\n# Remove the 'price' column from X_train if it's mistakenly included\nif 'price' in X_train.columns:\n    X_train.drop(columns=['price'], inplace=True)\n\n# One-hot encode the categorical features\nencoder = OneHotEncoder(sparse=False, drop='first')  # You can customize drop parameter as needed\nX_train_encoded = encoder.fit_transform(X_train[categorical_features])\n\n# Calculate mutual information scores for one-hot encoded categorical features\nmi_scores = mutual_info_classif(X_train_encoded, y_train, discrete_features=True, random_state=42)\n\n# Round the scores to 2 decimals\nrounded_mi_scores = [round(score, 2) for score in mi_scores]\n\n# Find the variable with the lowest mutual information score\nlowest_mi_score_index = rounded_mi_scores.index(min(rounded_mi_scores))\nprint(f'Response - {categorical_features[lowest_mi_score_index]}')\n","metadata":{"execution":{"iopub.status.busy":"2023-09-30T09:30:36.405958Z","iopub.execute_input":"2023-09-30T09:30:36.406284Z","iopub.status.idle":"2023-09-30T09:30:38.846012Z","shell.execute_reply.started":"2023-09-30T09:30:36.406248Z","shell.execute_reply":"2023-09-30T09:30:38.844418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Question 4:**","metadata":{}},{"cell_type":"code","source":"# Concatenate the training and validation datasets vertically\nX_combined = pd.concat([X_train, X_val], axis=0)\ny_combined = pd.concat([y_train, y_val], axis=0)\n\n# Define the list of categorical features\ncategorical_features = ['make', 'model', 'transmission_type', 'vehicle_style']\n\n# Initialize an empty encoder to store categories\nencoder = OneHotEncoder(categories='auto', sparse=False)\n\n# Fit the encoder on the combined data\nX_combined_encoded = encoder.fit_transform(X_combined[categorical_features])\n\n# Split the combined dataset back into training and validation parts\nX_train_encoded = X_combined_encoded[:len(X_train)]\nX_val_encoded = X_combined_encoded[len(X_train):]\n\n# Create a pipeline with Logistic Regression\nmodel = LogisticRegression(solver='liblinear', C=10, max_iter=1000, random_state=42)\n\n# Fit the model on the training data\nmodel.fit(X_train_encoded, y_train)\n\n# Predict on the validation data\ny_pred = model.predict(X_val_encoded)\n\n# Calculate accuracy on the validation dataset\naccuracy = accuracy_score(y_val, y_pred)\nprint(f'Response - {round(accuracy, 2)}')\n","metadata":{"execution":{"iopub.status.busy":"2023-09-30T09:30:38.847735Z","iopub.execute_input":"2023-09-30T09:30:38.848173Z","iopub.status.idle":"2023-09-30T09:30:39.053472Z","shell.execute_reply.started":"2023-09-30T09:30:38.848130Z","shell.execute_reply":"2023-09-30T09:30:39.051731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Question 5:**","metadata":{}},{"cell_type":"code","source":"# Concatenate the training and validation datasets vertically\nX_combined = pd.concat([X_train, X_val], axis=0)\ny_combined = pd.concat([y_train, y_val], axis=0)\n\n# Define the list of categorical features\ncategorical_features = ['make', 'model', 'transmission_type', 'vehicle_style']\n\n# Initialize an empty encoder to store categories\nencoder = OneHotEncoder(categories='auto', sparse=False)\n\n# Fit the encoder on the combined data\nX_combined_encoded = encoder.fit_transform(X_combined[categorical_features])\n\n# Split the combined dataset back into training and validation parts\nX_train_encoded = X_combined_encoded[:len(X_train)]\nX_val_encoded = X_combined_encoded[len(X_train):]\n\n# Create a list of features to exclude one at a time\nfeatures_to_exclude = ['year', 'engine_hp', 'transmission_type', 'city_mpg']\n\n# Initialize a dictionary to store accuracy differences\naccuracy_differences = {}\n\n# Train and evaluate models with each feature excluded\nfor feature in features_to_exclude:\n    # Create a copy of the dataset with the feature excluded\n    X_train_exclude = X_train_encoded.copy()\n    X_val_exclude = X_val_encoded.copy()\n    \n    # Find the index of the feature to be excluded\n    feature_index = X_train.columns.get_loc(feature)\n    \n    # Remove the corresponding column from the copied datasets\n    X_train_exclude = np.delete(X_train_exclude, feature_index, axis=1)\n    X_val_exclude = np.delete(X_val_exclude, feature_index, axis=1)\n    \n    # Create and fit the logistic regression model without the feature\n    model_exclude = LogisticRegression(solver='liblinear', C=10, max_iter=1000, random_state=42)\n    model_exclude.fit(X_train_exclude, y_train)\n    \n    # Calculate accuracy without the feature\n    y_pred_exclude = model_exclude.predict(X_val_exclude)\n    accuracy_exclude = accuracy_score(y_val, y_pred_exclude)\n    \n    # Calculate accuracy difference\n    accuracy_difference = accuracy - accuracy_exclude\n    \n    # Store accuracy difference in the dictionary\n    accuracy_differences[feature] = accuracy_difference\n\n# Find the feature with the smallest difference\nsmallest_difference_feature = min(accuracy_differences, key=accuracy_differences.get)\nprint(f'Response - {smallest_difference_feature}')\n","metadata":{"execution":{"iopub.status.busy":"2023-09-30T09:30:39.055938Z","iopub.execute_input":"2023-09-30T09:30:39.057566Z","iopub.status.idle":"2023-09-30T09:30:39.891183Z","shell.execute_reply.started":"2023-09-30T09:30:39.057505Z","shell.execute_reply":"2023-09-30T09:30:39.889775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Question 6:**","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import Ridge\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import OneHotEncoder\nimport numpy as np\nimport pandas as pd\n\n# Concatenate the training and validation datasets vertically\nX_combined = pd.concat([X_train, X_val], axis=0)\ny_combined = pd.concat([y_train, y_val], axis=0)\n\n# Define the list of categorical features\ncategorical_features = ['make', 'model', 'transmission_type', 'city_mpg']\n\n# Initialize an encoder to store categories\nencoder = OneHotEncoder(categories='auto', sparse=False)\n\n# Fit the encoder on the combined data\nX_combined_encoded = encoder.fit_transform(X_combined[categorical_features])\n\n# Split the combined dataset back into training and validation parts\nX_train_encoded = X_combined_encoded[:len(X_train)]\nX_val_encoded = X_combined_encoded[len(X_train):]\n\n# Apply logarithmic transformation to price\ny_train_log = np.log1p(y_train)\ny_val_log = np.log1p(y_val)\n\n# Initialize a dictionary to store RMSE scores\nrmse_scores = {}\n\n# Try different alpha values for Ridge regression\nalphas = [0, 0.01, 0.1, 1, 10]\n\nfor alpha in alphas:\n    # Create and fit the Ridge regression model\n    ridge_model = Ridge(alpha=alpha, solver='sag', random_state=42)\n    ridge_model.fit(X_train_encoded, y_train_log)\n    \n    # Predict on the validation set and convert predictions back to original scale\n    y_pred_log = ridge_model.predict(X_val_encoded)\n    y_pred = np.expm1(y_pred_log)\n    \n    # Calculate RMSE\n    rmse = np.sqrt(mean_squared_error(np.expm1(y_val_log), y_pred))\n    \n    # Store RMSE in the dictionary\n    rmse_scores[alpha] = round(rmse, 3)\n\n# Print RMSE scores for all alpha values\nfor alpha, rmse in rmse_scores.items():\n    print(f\"Alpha = {alpha}: RMSE = {rmse}\")\n\nbest_alpha = min(rmse_scores, key=rmse_scores.get)\nprint(f'Response - {best_alpha}')","metadata":{"execution":{"iopub.status.busy":"2023-09-30T09:33:25.497504Z","iopub.execute_input":"2023-09-30T09:33:25.497878Z","iopub.status.idle":"2023-09-30T09:34:34.400096Z","shell.execute_reply.started":"2023-09-30T09:33:25.497849Z","shell.execute_reply":"2023-09-30T09:34:34.398707Z"},"trusted":true},"execution_count":null,"outputs":[]}]}